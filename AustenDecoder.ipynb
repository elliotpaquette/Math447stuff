{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elliotpaquette/Math447stuff/blob/main/AustenDecoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZq22khy9I_S"
      },
      "source": [
        "**The python version of decipher example**\n",
        "\n",
        "The first script encodes.  The second decodes.\n",
        "\n",
        "To run the decryption, you need the file AustenCount.txt, which was made by Dobrow and which is available at:\n",
        "https://github.com/elliotpaquette/Math447stuff/blob/main/AustenCount.txt\n",
        "It contains nearest-neighbor letter pair (a-z and ' ') frequencies from the complete works of Jane Austen.  \n",
        "\n",
        "If using google colab, you can put it in your google drive which will be mounted by default at /content/drive/MyDrive.  You'll need to adjust the path used below.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import numpy.linalg as npa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas\n",
        "import pickle\n",
        "\n",
        "import time\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display, HTML, Markdown\n",
        "\n",
        "import textwrap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJXZ84nfMiP-",
        "outputId": "688ff0dd-e893-4758-dbc5-1d1adfda7ef5"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path='/content/drive/MyDrive/ColabTemp/AustenCount.txt'\n",
        "PATH ='./AustenCount.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szNXD5TtABcx"
      },
      "source": [
        "This tests loading the AustenCount file and encrypts a string (they have nothing to do with one another)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abV3F9lK9Kx7",
        "outputId": "01a9add5-9a50-49e2-edc5-9f21839f3142"
      },
      "outputs": [],
      "source": [
        "#scrambled = ' hvptbhwqtwxjcoqwpverwqohwxjmzqwmevhwtxwxjcoqwpverwjzwytewktwitqwqsvlwsrteqwxjcoqwpverwqohwzhptikwmevhwtxwxjcoqwpverwjzwytewktwitqwqsvlwsrteqwxjcoqwpverwqojmkwmevhwtxwxjcoqwpverwztbhtihwyhvvzwzqtuwcthzwvjbuwqsuzwteqwqohwxjcoqwjzwtghmwxtemqowmevhwtivywq twzqekhiqzwqtwswxjcoqwxjxqowmevhwtihwxjcoqwsqwswqjbhwbsmqvhqzwzjnqowmevhwitwzojmqzwitwzothzwzhghiqowmevhwxjcoqzw jvvwctwtiwszwvticwszwqohywosghwqtwsikwqohwhjcoqowsikwxjisvwmevhwjxwqojzwjzwytemwxjmzqwijcoqwsqwxjcoqwpverwytewosghwqtwxjcoq'\n",
        "original = 'welcome to fight club the first rule of fight club is you do not talk about fight club the second rule of fight club is you do not talk about fight club'# third rule of fight club someone yells stop goes limp taps out the fight is over fourth rule only two students to a fight fifth rule one fight at a time martlets sixth rule no shirts no shoes seventh rule fights will go on as long as they have to and the eighth and final rule if this is your first night at fight club you have to fight also i really needed some extra words so i decided to add a bunch of random stuff at the end about probability and white rabbits and how coincidences are sometimes explained by randomness also zebras have stripes which are very cool and known well to prevent them from attack by jaguars'\n",
        "#original = 'i know why you are here mcgill neo i know what you have been doing why you hardly sleep why you live alone and why night after night you sit by your computer you are looking for mycourses updates i know because i was once looking for the same thing and when maxime rvc found me he told me i was not really looking for him i was looking for an answer it is the question that drives us mcgill neo it is the question that brought you here you know the question just as i did what is the matrix the answer is out there mcgill neo and it is looking for you and it will find you if you want it to coincidences in general are great stumbling blocks in the way of that class of thinkers who have been educated to know nothing of the theory of probabilities that theory to which the most glorious objects of human research are indebted for the most glorious of illustrations edgar allen poe the murders in the rue morgue morpheus this is your last chance after this there is no turning back you take the blue pill the story ends you wake up in your bed and believe whatever you want to believe you take the red pill you stay in wonderland and i show you how deep the rabbit hole goes'\n",
        "s=np.array(list(original))\n",
        "\n",
        "\n",
        "clear_output(wait=True)\n",
        "\n",
        "#time.sleep(0.5)\n",
        "\n",
        "#print(npa.matrix_power(P,2))\n",
        "\n",
        "#clear_output(wait=True)\n",
        "\n",
        "df = pandas.read_csv(PATH,sep='\\t',header=None)\n",
        "alphabeta = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
        "dalphanum = dict(zip(alphabeta, np.arange(0,27)))\n",
        "dnumalpha = dict(zip(np.arange(0,27),alphabeta))\n",
        "df=df.rename(index=dnumalpha,columns=dnumalpha)\n",
        "print(df)\n",
        "\n",
        "n=1000\n",
        "for j in range(n):\n",
        "  swap = npr.choice(alphabeta,size=2,replace=False)\n",
        "  s0 = np.where(s==swap[0])\n",
        "  s1 = np.where(s==swap[1])\n",
        "  s[s0] = swap[1]\n",
        "  s[s1] = swap[0]\n",
        "  #print(''.join(s[1:50]))\n",
        "  #clear_output(wait=True)\n",
        "  #time.sleep(0.1)\n",
        "\n",
        "print(''.join(s))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FsP7_p9NK3C"
      },
      "source": [
        "Decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYro71BmNMt8",
        "outputId": "46f81ba5-9197-4e56-91cc-8fac52927abe"
      },
      "outputs": [],
      "source": [
        "wrapper = textwrap.TextWrapper(width=100,\n",
        "    initial_indent=\" \" * 4,\n",
        "    subsequent_indent=\" \" * 4,\n",
        "    break_long_words=False,\n",
        "    break_on_hyphens=False)\n",
        "\n",
        "\n",
        "scrambled = (\"kujratuibaiyfqcbirjpeibcuiyfzwbizpjuiayiyfqcbirjpeifwioapigaisabibhjliheapbiyfqcbirjpeibcuiwurasgizpjuiayiyfqcbirjpeifwioapigaisabibhjliheapbiyfqcbirjpeibcfzgizpjuiayiyfqcbirjpeiwatuasuioujjwiwbadiqauwijftdibhdwiapbibcuiyfqcbifwiavuziyapzbcizpjuiasjoibkaiwbpgusbwibaihiyfqcbiyfybcizpjuiasuiyfqcbihbihibftuithzbjubwiwfxbcizpjuisaiwcfzbwisaiwcauwiwuvusbcizpjuiyfqcbwikfjjiqaiasihwijasqihwibcuoichvuibaihsgibcuiufqcbcihsgiyfshjizpjuifyibcfwifwioapziyfzwbisfqcbihbiyfqcbirjpeioapichvuibaiyfqcbihjwaifizuhjjoisuugugiwatuiuxbzhikazgwiwaifigurfgugibaihggihiepsrciayizhsgatiwbpyyihbibcuiusgiheapbidzaehefjfboihsgikcfbuizheefbwihsgicakirafsrfgusruwihzuiwatubftuwiuxdjhfsugieoizhsgatsuwwihjwaimuezhwichvuiwbzfduwikcfrcihzuivuzoiraajihsgilsaksikujjibaidzuvusbibcutiyzatihbbhrlieoi hqphzw\")\n",
        "#scrambled =(\"tzwjfyzerfespkbrejwhxerbzespaoreahwzefsespkbrejwhxepoe fheifecfrerqwgeqxfhrespkbrejwhxerbzeozjfcieahwzefsespkbrejwhxepoe fheifecfrerqwgeqxfhrespkbrejwhx\")\n",
        "s=np.array(list(scrambled))\n",
        "\n",
        "\n",
        "df = pandas.read_csv(PATH,sep='\\t',header=None)\n",
        "alphabeta = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
        "dalphanum = dict(zip(alphabeta, np.arange(0,27)))\n",
        "dnumalpha = dict(zip(np.arange(0,27),alphabeta))\n",
        "df=df.rename(index=dnumalpha,columns=dnumalpha)\n",
        "df=df.apply( (lambda x : np.log(1+x)))\n",
        "\n",
        "\n",
        "logscore = lambda st : sum([df[b][a] for a, b in zip(s[0:-1],s[1:])])\n",
        "\n",
        "\n",
        "n=10000\n",
        "for j in range(n):\n",
        "  swap = npr.choice(alphabeta,size=2,replace=False)\n",
        "  s0 = np.where(s==swap[0])\n",
        "  s1 = np.where(s==swap[1])\n",
        "  x = logscore(s)\n",
        "  s[s0] = swap[1]\n",
        "  s[s1] = swap[0]\n",
        "  y = x-logscore(s)\n",
        "  if (y > npr.exponential(1)-0.5):# and (j % 500 != 0):\n",
        "    #print('wentback\\n')\n",
        "    s[s1] = swap[1]\n",
        "    s[s0] = swap[0]\n",
        "  else:  \n",
        "    text = ''.join(s)\n",
        "    colored_text = text\n",
        "    new_text = \"\"\n",
        "    i = 0\n",
        "    while i < len(colored_text):\n",
        "        if colored_text[i] in swap:  # Check if character is either of the swapped letters\n",
        "            new_text += f'<span style=\"color: red\">{colored_text[i]}</span>'\n",
        "        else:\n",
        "            new_text += colored_text[i]\n",
        "        i += 1\n",
        "    colored_text = new_text\n",
        "    clear_output(wait=True)\n",
        "    display(HTML((wrapper.fill('['+str(j) +']'+ colored_text))))\n",
        "    time.sleep(0.01)\n",
        "\n",
        "#  if j % 50 == 0:\n",
        "display(HTML((wrapper.fill('['+str(j) +']'+ ''.join(s)))))\n",
        "\n",
        "\n",
        "#print(wrapper.fill(''.join(s)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's add an annealing schedule to the decryption.  We'll start with a high temperature and then lower it as we get closer to the solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wrapper = textwrap.TextWrapper(width=100,\n",
        "    initial_indent=\" \" * 4,\n",
        "    subsequent_indent=\" \" * 4,\n",
        "    break_long_words=False,\n",
        "    break_on_hyphens=False)\n",
        "\n",
        "\n",
        "scrambled = (\"kujratuibaiyfqcbirjpeibcuiyfzwbizpjuiayiyfqcbirjpeifwioapigaisabibhjliheapbiyfqcbirjpeibcuiwurasgizpjuiayiyfqcbirjpeifwioapigaisabibhjliheapbiyfqcbirjpeibcfzgizpjuiayiyfqcbirjpeiwatuasuioujjwiwbadiqauwijftdibhdwiapbibcuiyfqcbifwiavuziyapzbcizpjuiasjoibkaiwbpgusbwibaihiyfqcbiyfybcizpjuiasuiyfqcbihbihibftuithzbjubwiwfxbcizpjuisaiwcfzbwisaiwcauwiwuvusbcizpjuiyfqcbwikfjjiqaiasihwijasqihwibcuoichvuibaihsgibcuiufqcbcihsgiyfshjizpjuifyibcfwifwioapziyfzwbisfqcbihbiyfqcbirjpeioapichvuibaiyfqcbihjwaifizuhjjoisuugugiwatuiuxbzhikazgwiwaifigurfgugibaihggihiepsrciayizhsgatiwbpyyihbibcuiusgiheapbidzaehefjfboihsgikcfbuizheefbwihsgicakirafsrfgusruwihzuiwatubftuwiuxdjhfsugieoizhsgatsuwwihjwaimuezhwichvuiwbzfduwikcfrcihzuivuzoiraajihsgilsaksikujjibaidzuvusbibcutiyzatihbbhrlieoi hqphzw\")\n",
        "#scrambled =(\"tzwjfyzerfespkbrejwhxerbzespaoreahwzefsespkbrejwhxepoe fheifecfrerqwgeqxfhrespkbrejwhxerbzeozjfcieahwzefsespkbrejwhxepoe fheifecfrerqwgeqxfhrespkbrejwhx\")\n",
        "s=np.array(list(scrambled))\n",
        "\n",
        "\n",
        "df = pandas.read_csv(PATH,sep='\\t',header=None)\n",
        "alphabeta = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',' ']\n",
        "dalphanum = dict(zip(alphabeta, np.arange(0,27)))\n",
        "dnumalpha = dict(zip(np.arange(0,27),alphabeta))\n",
        "df=df.rename(index=dnumalpha,columns=dnumalpha)\n",
        "df=df.apply( (lambda x : np.log(1+x)))\n",
        "\n",
        "\n",
        "logscore = lambda st : sum([df[b][a] for a, b in zip(s[0:-1],s[1:])])\n",
        "\n",
        "\n",
        "n=10000\n",
        "for j in range(n):\n",
        "  swap = npr.choice(alphabeta,size=2,replace=False)\n",
        "  s0 = np.where(s==swap[0])\n",
        "  s1 = np.where(s==swap[1])\n",
        "  x = logscore(s)\n",
        "  s[s0] = swap[1]\n",
        "  s[s1] = swap[0]\n",
        "  y = x-logscore(s)\n",
        "  if (y > npr.exponential(1) - 1.0 + (j/1000)):# and (j % 500 != 0):\n",
        "    #print('wentback\\n')\n",
        "    s[s1] = swap[1]\n",
        "    s[s0] = swap[0]\n",
        "  else:\n",
        "    text = ''.join(s)\n",
        "    colored_text = text\n",
        "    new_text = \"\"\n",
        "    i = 0\n",
        "    while i < len(colored_text):\n",
        "        if colored_text[i] in swap:  # Check if character is either of the swapped letters\n",
        "            new_text += f'<span style=\"color: red\">{colored_text[i]}</span>'\n",
        "        else:\n",
        "            new_text += colored_text[i]\n",
        "        i += 1\n",
        "    colored_text = new_text\n",
        "    clear_output(wait=True)\n",
        "    display(HTML((wrapper.fill('['+str(j) +']'+ colored_text))))\n",
        "    time.sleep(0.01)\n",
        "\n",
        "#  if j % 50 == 0:\n",
        "display(HTML((wrapper.fill('['+str(j) +']'+ ''.join(s)))))\n",
        "\n",
        "\n",
        "#print(wrapper.fill(''.join(s)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Putting weights into the proposal distribution \n",
        "Let's change the proposal distribution.  Instead of using a random swap, let's look at all the current adjacent pairs of letters ab.  Now make an array of letter weights w.  Now look at the bigram frequencies in df[a][b], and add (1/(df[a][b]+1)) to w[a] and to w[b].  Finally select a letter with probability proportional to w and another letter uniformly at random.  Then accept the swap with the same rule as above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 10000\n",
        "for j in range(n):\n",
        "\n",
        "    pairs = list(zip(s[:-1], s[1:]))\n",
        "    w = {letter: 1 for letter in alphabeta}\n",
        "\n",
        "    for a, b in pairs:\n",
        "        w[a] += 1/np.power(df[a][b] + 1, 0.1)\n",
        "        w[b] += 1/np.power(df[a][b] + 1, 0.1)\n",
        "\n",
        "    # Convert dictionary w to array, preserving order of alphabeta\n",
        "    w_array = np.array([w[letter] for letter in alphabeta])\n",
        "    w_array = w_array / np.sum(w_array)\n",
        "    # Select first letter weighted by w, second letter uniform random\n",
        "    swap = np.array([\n",
        "        npr.choice(alphabeta, p=w_array),\n",
        "        npr.choice(alphabeta)\n",
        "    ])\n",
        "    \n",
        "    s0 = np.where(s==swap[0])\n",
        "    s1 = np.where(s==swap[1])\n",
        "    x = logscore(s)\n",
        "    s[s0] = swap[1]\n",
        "    s[s1] = swap[0]\n",
        "    y = x-logscore(s)\n",
        "    if (y > npr.exponential(1) - 0.5):\n",
        "        s[s1] = swap[1]\n",
        "        s[s0] = swap[0]\n",
        "    else:\n",
        "        text = ''.join(s)\n",
        "        colored_text = text\n",
        "        new_text = \"\"\n",
        "        i = 0\n",
        "        while i < len(colored_text):\n",
        "            if colored_text[i] in swap:\n",
        "                new_text += f'<span style=\"color: red\">{colored_text[i]}</span>'\n",
        "            else:\n",
        "                new_text += colored_text[i]\n",
        "            i += 1\n",
        "        colored_text = new_text\n",
        "        clear_output(wait=True)\n",
        "        display(HTML((wrapper.fill('['+str(j) +']'+ colored_text))))\n",
        "        time.sleep(0.01)\n",
        "\n",
        "display(HTML((wrapper.fill('['+str(j) +']'+ ''.join(s)))))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adding higher order n-grams to the score function\n",
        "\n",
        "In the file trigram_counts.pkl, we have the trigram counts for the complete works of Jane Austen.  We can use these to calculate the score function.  We'll use the same proposal distribution as before, but we'll use the trigram counts to calculate the score function.  We'll use the same annealing schedule as before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wrapper = textwrap.TextWrapper(width=100,\n",
        "    initial_indent=\" \" * 4,\n",
        "    subsequent_indent=\" \" * 4,\n",
        "    break_long_words=False,\n",
        "    break_on_hyphens=False)\n",
        "\n",
        "\n",
        "scrambled = (\"kujratuibaiyfqcbirjpeibcuiyfzwbizpjuiayiyfqcbirjpeifwioapigaisabibhjliheapbiyfqcbirjpeibcuiwurasgizpjuiayiyfqcbirjpeifwioapigaisabibhjliheapbiyfqcbirjpeibcfzgizpjuiayiyfqcbirjpeiwatuasuioujjwiwbadiqauwijftdibhdwiapbibcuiyfqcbifwiavuziyapzbcizpjuiasjoibkaiwbpgusbwibaihiyfqcbiyfybcizpjuiasuiyfqcbihbihibftuithzbjubwiwfxbcizpjuisaiwcfzbwisaiwcauwiwuvusbcizpjuiyfqcbwikfjjiqaiasihwijasqihwibcuoichvuibaihsgibcuiufqcbcihsgiyfshjizpjuifyibcfwifwioapziyfzwbisfqcbihbiyfqcbirjpeioapichvuibaiyfqcbihjwaifizuhjjoisuugugiwatuiuxbzhikazgwiwaifigurfgugibaihggihiepsrciayizhsgatiwbpyyihbibcuiusgiheapbidzaehefjfboihsgikcfbuizheefbwihsgicakirafsrfgusruwihzuiwatubftuwiuxdjhfsugieoizhsgatsuwwihjwaimuezhwichvuiwbzfduwikcfrcihzuivuzoiraajihsgilsaksikujjibaidzuvusbibcutiyzatihbbhrlieoi hqphzw\")\n",
        "#scrambled =(\"tzwjfyzerfespkbrejwhxerbzespaoreahwzefsespkbrejwhxepoe fheifecfrerqwgeqxfhrespkbrejwhxerbzeozjfcieahwzefsespkbrejwhxepoe fheifecfrerqwgeqxfhrespkbrejwhx\")\n",
        "s=np.array(list(scrambled))\n",
        "\n",
        "with open('trigram_counts.pkl', 'rb') as f:\n",
        "    trigram_counts = pickle.load(f)\n",
        "\n",
        "logscore = lambda st : sum([np.log(1+trigram_counts[(a,b,c)]) for a, b, c in zip(st[0:-2],st[1:-1],st[2:])])\n",
        "\n",
        "\n",
        "n=100000\n",
        "for j in range(n):\n",
        "  swap = npr.choice(alphabeta,size=2,replace=False)\n",
        "  s0 = np.where(s==swap[0])\n",
        "  s1 = np.where(s==swap[1])\n",
        "  x = logscore(s)\n",
        "  s[s0] = swap[1]\n",
        "  s[s1] = swap[0]\n",
        "  y = x-logscore(s)\n",
        "  if (y > npr.exponential(1) - 1.0 + (j/10000)):# and (j % 500 != 0):\n",
        "    #print('wentback\\n')\n",
        "    s[s1] = swap[1]\n",
        "    s[s0] = swap[0]\n",
        "  else:\n",
        "    text = ''.join(s)\n",
        "    colored_text = text\n",
        "    new_text = \"\"\n",
        "    i = 0\n",
        "    while i < len(colored_text):\n",
        "        if colored_text[i] in swap:  # Check if character is either of the swapped letters\n",
        "            new_text += f'<span style=\"color: red\">{colored_text[i]}</span>'\n",
        "        else:\n",
        "            new_text += colored_text[i]\n",
        "        i += 1\n",
        "    colored_text = new_text\n",
        "    clear_output(wait=True)\n",
        "    display(HTML((wrapper.fill('['+str(j) +']'+ colored_text))))\n",
        "    time.sleep(0.01)\n",
        "\n",
        "#  if j % 50 == 0:\n",
        "display(HTML((wrapper.fill('['+str(j) +']'+ ''.join(s)))))\n",
        "\n",
        "\n",
        "#print(wrapper.fill(''.join(s)))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMwNN7pqOcQI1YfgNsaolGH",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1q5BNTO8eFsDaM8R7iZa_NofLmrSpqRWA",
      "name": "AustenDecoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "e-py",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
